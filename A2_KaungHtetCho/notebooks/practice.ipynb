{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/10 09:45:34 INFO mlflow.tracking.fluent: Experiment with name 'st124092-A2Assignment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/333605939037841023', creation_time=1739155534650, experiment_id='333605939037841023', last_update_time=1739155534650, lifecycle_stage='active', name='st124092-A2Assignment', tags={}>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "import os\n",
    "\n",
    "\n",
    "mlflow.set_tracking_uri('http://localhost:8080')\n",
    "\n",
    "os.environ['LOGNAME'] = 'st124092'\n",
    "\n",
    "mlflow.set_experiment('st124092-A2Assignment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['age', 'sex', 'bmi', 'bp', 's1', 's2', 's3', 's4', 's5', 's6']\n"
     ]
    }
   ],
   "source": [
    "diabetes = load_diabetes()\n",
    "print(f'Features: {diabetes.feature_names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: (442, 10)\n",
      "target: (442,)\n"
     ]
    }
   ],
   "source": [
    "X = diabetes.data   \n",
    "y = diabetes.target\n",
    "\n",
    "print(f'features: {X.shape}')\n",
    "print(f'target: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "442\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "m = X.shape[0] # samples\n",
    "n = X.shape[1] # features\n",
    "\n",
    "print(m)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (309, 10)\n",
      "X_test: (133, 10)\n"
     ]
    }
   ],
   "source": [
    "scaler  = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test  = scaler.transform(X_test)\n",
    "\n",
    "print(f'X_train: {X_train.shape}')\n",
    "print(f'X_test: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones((3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intercept: (309, 1)\n",
      "X_train: (309, 11)\n",
      "intercept: (133, 1)\n",
      "X_test: (133, 11)\n"
     ]
    }
   ],
   "source": [
    "intercept = np.ones((X_train.shape[0], 1))\n",
    "print(f'intercept: {intercept.shape}')\n",
    "\n",
    "X_train = np.concatenate((intercept, X_train), axis = 1)\n",
    "print(f'X_train: {X_train.shape}')\n",
    "\n",
    "intercept = np.ones((X_test.shape[0], 1))\n",
    "print(f'intercept: {intercept.shape}')\n",
    "\n",
    "X_test = np.concatenate((intercept, X_test), axis = 1)\n",
    "print(f'X_test: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFold(n_splits=5, random_state=None, shuffle=False)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(n_splits=5)\n",
    "\n",
    "print(kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4185849342.py, line 24)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 24\u001b[0;36m\u001b[0m\n\u001b[0;31m    for\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "class LinarRegression(object):\n",
    "\n",
    "    kfold = KFold(n_splits=5)\n",
    "\n",
    "    def __init__(self, regularization, lr=0.001, method='batch', num_epoches=500, batch_size=50, cv=kfold):\n",
    "        self.lr             = lr\n",
    "        self.num_epoches    = num_epoches\n",
    "        self.batch_size     = batch_size\n",
    "        self.method         = method\n",
    "        self.cv             = cv\n",
    "        self.regularization = regularization\n",
    "\n",
    "    def mse(self, ytrue, ypred):\n",
    "        return ((ypred - ytrue) ** 2).sum() / ytrue.shape[0]\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "\n",
    "        self.kfold_scores = list()\n",
    "\n",
    "        self.val_loss_old = np.infty\n",
    "\n",
    "        for \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_cross_train: (247, 11)\n",
      "y_cross_train: [168. 275. 310. 128. 121. 296. 187. 259.  49. 135.  59. 189. 124. 264.\n",
      "  88. 142. 232. 144. 242. 281. 219. 122.  90. 252. 241. 151.  63. 276.\n",
      "  63.  99. 281.  42.  53.  87. 131.  88.  37. 103.  53. 143. 249. 258.\n",
      "  88. 341.  49. 170. 233. 275. 206. 273. 237.  84. 150. 200.  25. 263.\n",
      "  97. 160. 321.  72. 297.  39.  31. 178.  71. 185. 175. 158.  68. 167.\n",
      "  99.  87. 160.  66. 200. 114.  51. 199. 265. 202.  89.  72. 292.  75.\n",
      " 131. 274.  53. 209. 155. 155. 270.  93.  71. 233. 141. 232. 306. 202.\n",
      "  66. 252. 214. 103.  47.  64.  78. 104. 129. 180.  96. 101.  74.  44.\n",
      " 118.  42. 202. 111. 124. 235. 163.  90. 179.  95.  86. 129. 115. 178.\n",
      " 104.  71. 150. 336.  61.  78. 164.  55.  63. 162.  59. 283. 302. 215.\n",
      "  54.  52. 107.  52. 248. 182. 308. 217. 158. 261.  68. 128. 139. 132.\n",
      " 115. 168. 214. 181.  85. 141. 245. 258. 252. 123.  65.  84. 179. 191.\n",
      " 198. 145. 248. 220. 283. 191. 265.  53. 268.  97. 138. 198. 122.  75.\n",
      " 262.  85. 230.  48.  65.  94.  63. 111. 185. 132.  80.  96. 220.  50.\n",
      " 216.  39.  71.  51. 237. 109. 161. 156. 113.  72. 275. 219. 243. 206.\n",
      "  79.  90.  72.  70. 118.  70. 154. 143.  84. 201. 109.  81. 275. 185.\n",
      "  95. 195. 110. 184.  77. 221. 137.  68.  49. 310.  59. 100.  78. 279.\n",
      " 107. 197. 148.  59. 192. 144. 135.  48. 141.]\n",
      "X_cross_val: [[ 1.00000000e+00 -6.99637037e-01  1.07043605e+00  1.18749824e+00\n",
      "  -2.24564190e-02  3.26240588e-01  7.66118698e-01 -9.40252919e-01\n",
      "   8.24158323e-01  3.38638710e-01  1.77209082e-01]\n",
      " [ 1.00000000e+00  6.12463411e-01 -9.34198733e-01  2.11271599e+00\n",
      "   1.58481602e+00 -1.93547646e-01 -2.05294982e-01 -1.25730451e+00\n",
      "   8.24158323e-01  1.25094031e+00  8.02499855e-01]\n",
      " [ 1.00000000e+00 -1.59360382e-01  1.07043605e+00 -2.66415376e-01\n",
      "   1.96717095e-01 -4.38153874e-01 -2.97472923e-01 -4.64675532e-01\n",
      "  -3.32062750e-03  2.56435203e-01  1.51711788e+00]\n",
      " [ 1.00000000e+00 -6.99637037e-01  1.07043605e+00  5.48657408e-01\n",
      "   1.43870034e+00 -2.76191304e+00 -2.36793128e+00 -1.17804161e+00\n",
      "  -1.02111974e+00 -6.44460170e-01  3.55863588e-01]\n",
      " [ 1.00000000e+00  9.98375307e-01  1.07043605e+00 -6.62937271e-01\n",
      "  -1.09421490e+00  1.15178661e+00 -4.22109339e-02  2.86436618e+00\n",
      "  -1.14524158e+00  4.78659994e-01  4.45190842e-01]\n",
      " [ 1.00000000e+00  9.21192928e-01 -9.34198733e-01 -1.56270405e-01\n",
      "   1.96717095e-01  1.45754439e+00  4.18678769e-01  2.07173720e+00\n",
      "  -8.30799578e-01  9.44348761e-01 -8.05390704e-01]\n",
      " [ 1.00000000e+00  4.58098652e-01 -9.34198733e-01  3.72425455e-01\n",
      "  -3.14687772e-01  1.91618107e+00  9.29202747e-01  1.35837112e+00\n",
      "  -3.32062750e-03  1.44386289e+00  1.07048161e+00]\n",
      " [ 1.00000000e+00  7.66828169e-01  1.07043605e+00 -2.22357388e-01\n",
      "   1.65266760e-03  8.16343599e-02  9.00840303e-01 -1.17804161e+00\n",
      "   1.17997427e+00 -5.41017479e-01  2.32106316e+00]\n",
      " [ 1.00000000e+00  9.21192928e-01  1.07043605e+00  1.36373019e+00\n",
      "   1.23659257e-01 -3.15850760e-01  1.56326169e-01 -1.65361900e+00\n",
      "   1.65163727e+00  7.18584106e-01 -3.58754438e-01]\n",
      " [ 1.00000000e+00  2.26551515e-01  1.07043605e+00 -1.50003905e+00\n",
      "  -1.04526615e+00 -1.08024522e+00 -2.14812234e+00  2.54731458e+00\n",
      "  -1.65827853e+00 -4.18892173e-01 -8.05390704e-01]\n",
      " [ 1.00000000e+00 -6.22454657e-01  1.07043605e+00 -5.08734312e-01\n",
      "  -3.87745610e-01  3.56816366e-01  3.40682050e-01  5.65742139e-01\n",
      "  -3.32062750e-03 -2.16333292e-01 -4.48081691e-01]\n",
      " [ 1.00000000e+00 -3.90907520e-01 -9.34198733e-01 -1.10351715e+00\n",
      "  -7.53034800e-01 -9.27366329e-01 -7.72543847e-01  4.07216344e-01\n",
      "  -8.30799578e-01 -1.45528567e+00 -6.26736198e-01]\n",
      " [ 1.00000000e+00  2.26551515e-01 -9.34198733e-01 -5.52792300e-01\n",
      "  -8.99150477e-01 -6.21608544e-01 -9.71080950e-01  1.67542271e+00\n",
      "  -1.65827853e+00 -1.53729252e+00  2.66536335e-01]\n",
      " [ 1.00000000e+00 -6.22454657e-01 -9.34198733e-01 -1.38989408e+00\n",
      "  -2.43336508e+00 -1.04966944e+00 -8.85993620e-01  1.09018549e-02\n",
      "  -8.30799578e-01 -7.53802633e-01 -1.80099931e-01]\n",
      " [ 1.00000000e+00  7.66828169e-01  1.07043605e+00  1.23155623e+00\n",
      "   4.15890610e-01 -9.27366329e-01 -7.37090793e-01 -9.40252919e-01\n",
      "  -3.32062750e-03  4.48374492e-01 -3.58754438e-01]\n",
      " [ 1.00000000e+00 -1.59360382e-01 -9.34198733e-01  8.35034332e-01\n",
      "   1.00035332e+00  6.01422594e-01 -4.88919415e-01  1.59615981e+00\n",
      "  -8.30799578e-01  1.14671098e+00  6.23845348e-01]\n",
      " [ 1.00000000e+00  1.38428720e+00 -9.34198733e-01 -1.27974911e+00\n",
      "  -8.99150477e-01 -5.29881209e-01 -5.03100636e-01  7.24267935e-01\n",
      "  -8.30799578e-01 -1.19254910e+00 -1.25202697e+00]\n",
      " [ 1.00000000e+00 -1.59360382e-01 -9.34198733e-01  1.29764321e+00\n",
      "   7.08121962e-01  2.04828030e-02  3.90316325e-01 -3.06149736e-01\n",
      "   7.11524780e-02 -3.71890646e-01  7.13172602e-01]\n",
      " [ 1.00000000e+00  2.26551515e-01 -9.34198733e-01  2.84309478e-01\n",
      "  -7.53034800e-01  9.68331935e-01  7.80299920e-01 -6.83610429e-02\n",
      "  -3.32062750e-03  9.91153629e-01 -1.43068148e+00]\n",
      " [ 1.00000000e+00  8.44010549e-01  1.07043605e+00  1.42981717e+00\n",
      "   1.23659257e-01  9.07180378e-01  4.11588158e-01 -3.85412634e-01\n",
      "   8.24158323e-01  1.60256679e+00  1.87442689e+00]\n",
      " [ 1.00000000e+00 -1.62582559e+00  1.07043605e+00 -3.98589341e-01\n",
      "   1.23659257e-01 -3.77002317e-01 -5.10191247e-01 -1.41583031e+00\n",
      "   8.24158323e-01  1.47119851e+00 -3.58754438e-01]\n",
      " [ 1.00000000e+00 -1.00836655e+00  1.07043605e+00 -5.30763306e-01\n",
      "   1.21952683e+00  1.73361695e-01  3.90316325e-01 -1.17804161e+00\n",
      "   1.65163727e+00  9.32352556e-01  3.55863588e-01]\n",
      " [ 1.00000000e+00 -1.59360382e-01 -9.34198733e-01  1.12141126e+00\n",
      "  -8.26092639e-01 -1.01909366e+00 -9.21446674e-01 -1.57435610e+00\n",
      "   9.06906218e-01  1.11445889e+00  1.24913612e+00]\n",
      " [ 1.00000000e+00  7.66828169e-01  1.07043605e+00  8.60485306e-02\n",
      "   6.35064124e-01  2.03937474e-01  4.47041212e-01 -5.43938430e-01\n",
      "   8.24158323e-01  3.38638710e-01  1.33846337e+00]\n",
      " [ 1.00000000e+00  3.03733894e-01  1.07043605e+00 -9.49314195e-01\n",
      "   1.29258467e+00  2.95664809e-01  4.28763958e-02  1.35837112e+00\n",
      "  -8.30799578e-01 -6.44460170e-01  8.02499855e-01]\n",
      " [ 1.00000000e+00  8.44010549e-01 -9.34198733e-01 -9.49314195e-01\n",
      "   6.84012876e-01  1.02948349e+00 -3.04563534e-01  8.03530833e-01\n",
      "  -2.68113892e-01  1.95832312e+00  1.77209082e-01]\n",
      " [ 1.00000000e+00  9.98375307e-01 -9.34198733e-01 -9.05256207e-01\n",
      "  -1.19138183e+00  1.06005927e+00  1.18446474e+00  7.24267935e-01\n",
      "  -3.32062750e-03 -5.41017479e-01 -1.34135422e+00]\n",
      " [ 1.00000000e+00 -8.54001795e-01 -9.34198733e-01  1.74164507e-01\n",
      "  -1.04526615e+00 -1.26369989e+00 -1.14834622e+00 -2.26886839e-01\n",
      "  -8.30799578e-01 -3.26265733e-01 -8.94717958e-01]\n",
      " [ 1.00000000e+00  1.30710482e+00 -9.34198733e-01  3.28367466e-01\n",
      "   4.15890610e-01  2.34513252e-01  5.39219152e-01 -7.81727123e-01\n",
      "   8.24158323e-01  4.48374492e-01  2.66536335e-01]\n",
      " [ 1.00000000e+00  1.15274007e+00  1.07043605e+00 -6.62937271e-01\n",
      "   1.23659257e-01  4.79119480e-01  5.32128541e-01  7.24267935e-01\n",
      "  -8.30799578e-01 -6.18107849e-01 -1.25202697e+00]\n",
      " [ 1.00000000e+00  9.98375307e-01 -9.34198733e-01  5.26628414e-01\n",
      "  -5.82810038e-01  5.70846815e-01  4.68313044e-01 -1.33656741e+00\n",
      "   1.85023222e+00  1.57700111e+00  7.13172602e-01]\n",
      " [ 1.00000000e+00  8.44010549e-01  1.07043605e+00  3.72425455e-01\n",
      "   1.21952683e+00 -7.12445323e-02 -6.75787988e-03 -6.23201328e-01\n",
      "  -3.32062750e-03  6.91838467e-01  1.77209082e-01]\n",
      " [ 1.00000000e+00 -1.08554893e+00 -9.34198733e-01 -1.34583609e+00\n",
      "  -2.21419156e+00 -1.00929754e-02 -2.97472923e-01  1.35837112e+00\n",
      "  -1.00457016e+00 -6.98344765e-01 -1.16269972e+00]\n",
      " [ 1.00000000e+00 -2.01173748e+00  1.07043605e+00 -1.87453195e+00\n",
      "  -1.26443967e+00 -4.99305431e-01 -6.37822242e-01 -1.47623941e-01\n",
      "  -3.32062750e-03  5.37854386e-01  8.78818285e-02]\n",
      " [ 1.00000000e+00 -1.16273131e+00 -9.34198733e-01  1.07735327e+00\n",
      "  -6.06919124e-01 -1.17197256e+00 -7.15818961e-01 -3.06149736e-01\n",
      "  -8.30799578e-01 -1.57957423e+00 -1.25202697e+00]\n",
      " [ 1.00000000e+00  9.21192928e-01 -9.34198733e-01 -5.52792300e-01\n",
      "  -3.14687772e-01  4.48543701e-01  4.99670066e-02  1.75468561e+00\n",
      "  -8.30799578e-01 -6.71205808e-01 -1.60933598e+00]\n",
      " [ 1.00000000e+00  4.58098652e-01 -9.34198733e-01  1.23155623e+00\n",
      "   1.07341115e+00 -7.13335880e-01 -1.05616828e+00 -6.23201328e-01\n",
      "  -3.32062750e-03  1.19941562e+00 -9.07726781e-02]\n",
      " [ 1.00000000e+00  2.26551515e-01  1.07043605e+00  1.99615481e-02\n",
      "   1.14646899e+00  6.62574151e-01  4.39950601e-01  8.82793731e-01\n",
      "  -8.30799578e-01  9.89112575e-02  1.60644513e+00]\n",
      " [ 1.00000000e+00 -1.62582559e+00  1.07043605e+00 -2.22357388e-01\n",
      "   2.69774934e-01 -7.74487437e-01 -4.39285139e-01 -3.06149736e-01\n",
      "  -3.32062750e-03 -6.98344765e-01  2.66536335e-01]\n",
      " [ 1.00000000e+00  2.31047575e+00  1.07043605e+00  1.08077525e-01\n",
      "   5.62006286e-01 -5.60456988e-01 -1.13117042e-01 -1.01951582e+00\n",
      "   8.24158323e-01  6.21360043e-02  1.69577239e+00]\n",
      " [ 1.00000000e+00 -1.08554893e+00 -9.34198733e-01  4.82570426e-01\n",
      "   1.23659257e-01  5.09695258e-01  4.54131823e-01  1.12058242e+00\n",
      "  -8.30799578e-01 -8.69438189e-01  1.77209082e-01]\n",
      " [ 1.00000000e+00 -1.62582559e+00 -9.34198733e-01 -9.71343190e-01\n",
      "  -9.72208315e-01 -5.91032766e-01 -4.74738193e-01  3.27953446e-01\n",
      "  -8.30799578e-01 -8.39939323e-01 -4.48081691e-01]\n",
      " [ 1.00000000e+00 -2.36542761e-01  1.07043605e+00 -3.98589341e-01\n",
      "  -7.53034800e-01 -4.07578095e-01  3.26500828e-01 -1.57435610e+00\n",
      "   1.65163727e+00  2.47707739e-02  4.45190842e-01]\n",
      " [ 1.00000000e+00  1.38428720e+00 -9.34198733e-01  1.12141126e+00\n",
      "   1.51175818e+00 -2.54699203e-01 -8.36359344e-01 -7.02464225e-01\n",
      "  -3.32062750e-03  1.65291153e+00  8.02499855e-01]\n",
      " [ 1.00000000e+00 -7.76819416e-01 -9.34198733e-01 -7.95111236e-01\n",
      "  -1.33749751e+00  5.09695258e-01  1.03556191e+00 -3.06149736e-01\n",
      "  -3.32062750e-03 -6.44460170e-01 -1.52000873e+00]\n",
      " [ 1.00000000e+00  2.26551515e-01  1.07043605e+00 -2.40964402e-02\n",
      "  -2.90578685e-01  9.37756157e-01  1.34754878e+00 -8.60990021e-01\n",
      "   1.31237090e+00  5.37854386e-01  7.13172602e-01]\n",
      " [ 1.00000000e+00  1.22992245e+00  1.07043605e+00  1.53996215e+00\n",
      "   4.88948448e-01  8.16343599e-02  4.32859990e-01 -1.17804161e+00\n",
      "   8.24158323e-01  6.64699510e-01  9.81154361e-01]\n",
      " [ 1.00000000e+00 -9.31184174e-01  1.07043605e+00  6.40195365e-02\n",
      "  -1.19138183e+00 -9.27366329e-01 -5.66916134e-01 -1.73288190e+00\n",
      "   1.65163727e+00  8.09440614e-01  4.45190842e-01]\n",
      " [ 1.00000000e+00 -1.70300797e+00 -9.34198733e-01 -1.52206804e+00\n",
      "  -1.26443967e+00 -1.81406390e+00 -1.63050775e+00 -5.43938430e-01\n",
      "  -8.30799578e-01 -3.71890646e-01 -1.78799049e+00]\n",
      " [ 1.00000000e+00  1.46146958e+00  1.07043605e+00 -1.78299399e-01\n",
      "   1.00035332e+00  1.39639283e+00 -4.93015447e-02 -1.17804161e+00\n",
      "   2.47911622e+00  2.80238401e+00  1.24913612e+00]\n",
      " [ 1.00000000e+00  1.69301672e+00  1.07043605e+00  1.08077525e-01\n",
      "  -1.44463009e-01  2.49712086e+00  2.70185545e+00 -7.02464225e-01\n",
      "   2.11502548e+00  1.19941562e+00  1.77209082e-01]\n",
      " [ 1.00000000e+00  4.58098652e-01  1.07043605e+00 -7.95111236e-01\n",
      "  -1.04526615e+00 -1.96694280e+00 -1.65887020e+00 -7.02464225e-01\n",
      "  -8.30799578e-01 -6.44460170e-01 -2.69427185e-01]\n",
      " [ 1.00000000e+00 -7.76819416e-01  1.07043605e+00  8.60485306e-02\n",
      "  -1.68572095e-01 -1.56945768e+00 -1.36815515e+00 -1.47623941e-01\n",
      "  -8.30799578e-01 -9.61081333e-01  7.13172602e-01]\n",
      " [ 1.00000000e+00 -3.90907520e-01 -9.34198733e-01 -7.51053248e-01\n",
      "  -6.06919124e-01  7.84877264e-01  4.39950601e-01  2.15100010e+00\n",
      "  -8.30799578e-01 -1.49579745e+00 -1.69866324e+00]\n",
      " [ 1.00000000e+00 -9.31184174e-01  1.07043605e+00 -1.12554615e+00\n",
      "  -8.99150477e-01 -1.81406390e+00 -1.57378287e+00 -6.83610429e-02\n",
      "  -8.30799578e-01 -1.53729252e+00 -6.26736198e-01]\n",
      " [ 1.00000000e+00  1.49369135e-01  1.07043605e+00  5.92715397e-01\n",
      "   8.54237639e-01 -1.00929754e-02  8.86659082e-01 -1.41583031e+00\n",
      "   1.65163727e+00 -4.91262725e-01  3.55863588e-01]\n",
      " [ 1.00000000e+00  1.49369135e-01 -9.34198733e-01  9.01121315e-01\n",
      "   5.62006286e-01  3.26240588e-01 -2.62019869e-01  5.65742139e-01\n",
      "  -8.30799578e-01  1.01416274e+00  8.02499855e-01]\n",
      " [ 1.00000000e+00 -1.08554893e+00 -9.34198733e-01  3.25822369e+00\n",
      "  -1.04526615e+00 -5.91032766e-01 -3.96741474e-01 -1.01951582e+00\n",
      "   8.24158323e-01  6.23401098e-01  2.66536335e-01]\n",
      " [ 1.00000000e+00 -8.21780025e-02  1.07043605e+00  5.92715397e-01\n",
      "   1.07341115e+00  9.37756157e-01  1.33336756e+00 -8.60990021e-01\n",
      "   1.65163727e+00  5.66763275e-01  6.23845348e-01]\n",
      " [ 1.00000000e+00  1.07555769e+00  1.07043605e+00 -2.22357388e-01\n",
      "   1.00035332e+00  1.18236238e+00 -3.82560253e-01 -3.06149736e-01\n",
      "   8.24158323e-01  2.59353204e+00 -3.58754438e-01]\n",
      " [ 1.00000000e+00 -5.45272278e-01 -9.34198733e-01  7.90976344e-01\n",
      "  -3.14687772e-01 -1.62971868e-01  2.86951742e-02 -6.83610429e-02\n",
      "  -3.32062750e-03 -2.37769135e-01 -8.05390704e-01]\n",
      " [ 1.00000000e+00 -2.16610224e+00 -9.34198733e-01 -1.41192307e+00\n",
      "  -2.36030724e+00 -1.60003345e+00 -1.59505470e+00  3.27953446e-01\n",
      "  -8.30799578e-01 -1.05705098e+00 -1.80099931e-01]]\n",
      "y_cross_val: [178. 270.  94. 170. 102. 134. 262.  81. 259.  77.  71. 181.  98.  77.\n",
      " 151. 166.  89. 109. 242. 295. 101. 163. 272. 311. 102.  90.  64. 210.\n",
      " 173.  91. 225. 178.  96.  94. 142. 118. 281.  85.  60. 277. 182.  69.\n",
      " 150. 303. 128. 259. 332. 144. 142. 248. 131. 129.  67.  52.  83. 244.\n",
      " 202. 346. 222. 197. 147.  55.]\n"
     ]
    }
   ],
   "source": [
    "cv = kfold\n",
    "''' \n",
    "  Generate indices to split data into training and test set\n",
    "  k = training --> 247\n",
    "  v = test --> 62\n",
    "  total samples = 309 / 5 = 62 \n",
    "''' \n",
    "for i, (k,v) in enumerate(cv.split(X_train)): \n",
    "\n",
    "    # print(f'i: {i}')\n",
    "    # print(f'k: {len(k)}')\n",
    "    # print(f'k: {k}')\n",
    "\n",
    "    # print(f'v: {len(v)}')    \n",
    "    # print(f'v: {v}')    \n",
    "\n",
    "    X_cross_train = X_train[k]\n",
    "    print(f'X_cross_train: {X_cross_train.shape}')\n",
    "    y_cross_train = y_train[k]\n",
    "    print(f'y_cross_train: {y_cross_train}')\n",
    "\n",
    "    X_cross_val = X_train[v]\n",
    "    print(f'X_cross_val: {X_cross_val}')\n",
    "    y_cross_val = y_train[v]\n",
    "    print(f'y_cross_val: {y_cross_val}')\n",
    "\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = np.zeros(X_cross_train.shape[1])\n",
    "\n",
    "theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(perm)\n",
      "features indices: [ 47  92  86 231 230  75 178  93 121  32 187   8 193 236  25  10  24  23\n",
      " 241  80 138 144  16  62 227 164   4 117   5  77 128  45  53 159 156 219\n",
      " 137 221 126 240 229  40 105  76  21  41 124 172 129  83 125  43 232 204\n",
      " 245 113 205 122 182  97 143 242  64  82 158  34 188 167 170 233 115 208\n",
      "  22 162  84 189 110 184 246  28 160  72 112 183 130 155 136   7   3  60\n",
      "  57 198 228 116 163 197 215  52  66  58 173  29 149 106 150   2 118  37\n",
      " 123 141  27 239 185 168 211  61  46 114  88  33 111 200  13 101 244  70\n",
      "  31   6 133 225 195  20  36 202 190 192 186 209  44 135  81 103   9 102\n",
      " 180 108 206  30 222 154 132  69 201  63  11  89 191 207  94  91 147 151\n",
      " 212 142 235  73  85  74 107 127 119 203 234 139  78 104 223 146  71 176\n",
      " 148   0 224  56  12  99 217  48 169 157 145  15  50 171  68 181 199  18\n",
      " 140 152  96 175  49  35 153  38  95 237  67 213 220 238  17  87  51   1\n",
      " 131  90  59 226 161 243  55 210 134 196 174 100  39 177  19  54  79 214\n",
      " 216  14  26 194 165  98 166 109 120  42  65 179 218]\n"
     ]
    }
   ],
   "source": [
    "# shuffle index\n",
    "perm = np.random.permutation(X_cross_train.shape[0])\n",
    "\n",
    "print(f'len(perm)')\n",
    "print(f'features indices: {perm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n",
      "X_cross_train: 247\n",
      "y_cross_train: 247\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(500):\n",
    "    '''\n",
    "    shuffle the features' indices\n",
    "    with replacement or no replacement\n",
    "    with replacement means just randomize\n",
    "    with no replacement means 0:50, 51:100, 101:150, ......300:323\n",
    "    shuffle your index\n",
    "    '''\n",
    "    X_cross_train = X_cross_train[perm]\n",
    "    y_cross_train = y_cross_train[perm]\n",
    "\n",
    "    print(f'X_cross_train: {len(X_cross_train)}')\n",
    "    print(f'y_cross_train: {len(y_cross_train)}')\n",
    "\n",
    "    # if stochastic batch:\n",
    "    for i in range(X_cross_train.shape[0]):\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cross_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_method_train: (1, 11)\n",
      "X_method_train: 1\n",
      "y_method_train: 48.0\n",
      "y_cross_train: 247\n"
     ]
    }
   ],
   "source": [
    "# stochastic method\n",
    "for i in range(X_cross_train.shape[0]):\n",
    "\n",
    "    X_method_train = X_cross_train[i].reshape(1,-1)\n",
    "    \n",
    "    print(f'X_method_train: {X_method_train.shape}')\n",
    "    print(f'X_method_train: {len(X_method_train)}')\n",
    "\n",
    "    y_method_train = y_cross_train[i]\n",
    "\n",
    "    print(f'y_method_train: {y_method_train}')\n",
    "    print(f'y_cross_train: {len(y_cross_train)}')\n",
    "\n",
    "    # _train -> Indicates that the name is meant for internal use only\n",
    "    # train_loss = _train(X_method_train, y_method_train)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cross_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_method_train: (50, 11)\n",
      "X_method_train: 50\n",
      "y_method_train: (50,)\n",
      "y_method_train: 50\n"
     ]
    }
   ],
   "source": [
    "# mini batch method\n",
    "batch_size = 50\n",
    "for i in range(0, X_cross_train.shape[0]):\n",
    "    '''\n",
    "    0: 50: 247 \n",
    "    #batch_idx = 0, 50, 100, 150\n",
    "    '''\n",
    "    X_method_train = X_cross_train[i:i+batch_size,:]\n",
    "\n",
    "    print(f'X_method_train: {X_method_train.shape}')\n",
    "    print(f'X_method_train: {len(X_method_train)}')\n",
    "\n",
    "    y_method_train = y_cross_train[i:i+batch_size]\n",
    "\n",
    "    print(f'y_method_train: {y_method_train.shape}')\n",
    "    print(f'y_method_train: {len(y_method_train)}')\n",
    "\n",
    "    # train_loss = _train(X_method_train, y_method_train)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cross_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# full batch method\n",
    "X_method_train = X_cross_train\n",
    "y_method_train = y_cross_train\n",
    "# train_loss = self._train(X_method_train, y_method_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "np.allclose\n",
    "Returns True if two arrays are element-wise equal within a tolerance.\n",
    "\n",
    "'''\n",
    "\n",
    "a = [2,3,4,5,6,7,9,9,9]\n",
    "b = [3,5,6,7,7,8,9,9,9]\n",
    "\n",
    "if np.allclose(a,b):\n",
    "    print('stopped')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Simulated validation losses over epochs\n",
    "validation_losses = [0.5, 0.4, 0.35, 0.34, 0.34, 0.34]\n",
    "\n",
    "# Initialize previous loss to infinity\n",
    "prev_loss = np.infty\n",
    "\n",
    "for epoch, current_loss in enumerate(validation_losses):\n",
    "    print(f\"Epoch {epoch}, validation loss: {current_loss}\")\n",
    "    \n",
    "    # If the current loss is almost equal to the previous loss, break the loop (early stopping)\n",
    "    if np.allclose(current_loss, prev_loss):\n",
    "        print(f\"Early stopping at epoch {epoch} because loss did not change significantly.\")\n",
    "        break\n",
    "    \n",
    "    # Update previous loss\n",
    "    prev_loss = current_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function for looping classnames\n",
    "import sys\n",
    "\n",
    "def str_to_class(classname):\n",
    "    return getattr(sys.modules[__name__], classname)\n",
    "\n",
    "''' \n",
    "sys.modules[__name__]: Gets the current module.\n",
    "getattr(...): Looks up the attribute (class) with the name provided in the string.\n",
    "Usage: If you have a class named Example defined in the module, calling str_to_class(\"Example\") returns the Example class object.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        self.value = \"Instance of Class A\"\n",
    "\n",
    "    def show(self):\n",
    "        print(self.value)\n",
    "\n",
    "class B:\n",
    "    def __init__(self):\n",
    "        self.value = \"Instance of Class B\"\n",
    "\n",
    "    def show(self):\n",
    "        print(self.value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string to class\n",
    "A_class = str_to_class(\"A\")\n",
    "B_class = str_to_class(\"B\")\n",
    "\n",
    "# Create instances\n",
    "a_instance = A_class()\n",
    "b_instance = B_class()\n",
    "\n",
    "# Use the instances\n",
    "a_instance.show()  # Outputs: Instance of Class A\n",
    "b_instance.show()  # Outputs: Instance of Class B\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso\n",
    "\n",
    "class Lasso:\n",
    "    def __int__(self, l): # lambda is a constant parameter\n",
    "        self.l = l\n",
    "    \n",
    "    def __call__(self, theta): # allows us to call class as method # theta is a dynamic input\n",
    "        return self.l * np.sum(np.abs(theta))\n",
    "\n",
    "    def derivation(self, theta):\n",
    "        return self.l * np.sign(theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge\n",
    "# Standalone class\n",
    "\n",
    "\n",
    "class Ridge:\n",
    "    def __int__(self, l): # lambda is a constant parameter\n",
    "        self.l = l\n",
    "    \n",
    "    def __call__(self, theta): # allows us to call class as method # theta is a dynamic input\n",
    "        return self.l * np.sum(np.square(theta))\n",
    "\n",
    "    def derivation(self, theta):\n",
    "        return self.l * 2 * theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "J(\\theta) = \\frac{1}{2}\\sum_{i=1}^m(h_\\theta(x^{(i)}) - y^{(i)})^2 + \\lambda(\\lambda \\sum_{j=1}^n |\\theta_j| + (1 - \\lambda) \\sum_{k=1}^n \\theta_k^2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ElasticNet\n",
    "\n",
    "class ElasticNet:\n",
    "    def __int__(self, l, l_ratio): # lambda is a constant parameter\n",
    "        self.l       = l\n",
    "        self.l_ratio = l_ratio\n",
    "    \n",
    "    def __call__(self, theta): # allows us to call class as method # theta is a dynamic input\n",
    "        l1 =  self.l * (1 - self.l_ratio) * np.sum(np.abs(theta))\n",
    "        l2 =  self.l * self.l_ratio * np.sum(np.square(theta))\n",
    "        return (l1 + l2)\n",
    "\n",
    "    def derivation(self, theta):\n",
    "        l1 = self.l * self.l_ratio * np.sign(theta)\n",
    "        l2 = 2 * self.l * (1 - self.l_ratio) * theta\n",
    "        return (l1 + l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Ridge Regression:\n",
    "Imagine you have many ingredients (predictors) in a recipe and you believe every one of them adds something, even if they are a bit similar. Ridge doesn't remove any ingredients; it just uses them in smaller, balanced amounts. This helps keep the overall mix stable, especially when some ingredients might be too similar.\n",
    "\n",
    "Lasso Regression:\n",
    "Think of Lasso like a strict chef who wants to simplify the recipe. The chef decides that only a few key ingredients really matter and completely leaves out the rest. Lasso automatically sets some of the coefficients to zero, effectively removing the less important predictors from the model.\n",
    "\n",
    "Elastic Net:\n",
    "Elastic Net is like a chef who uses a combination of both approaches. It sometimes reduces the influence of ingredients (like Ridge) and sometimes completely drops them (like Lasso). This approach is useful when you have many ingredients, and some are very similaryou want to keep the good parts of both techniques.\n",
    "\n",
    "In short, Ridge is best when you want to keep all predictors but control their impact, Lasso is best when you want to simplify by keeping only the important ones, and Elastic Net is a balanced mix that handles situations where predictors are numerous and possibly similar.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inhertis linear regression and has separate classes for each of this regularization algorithm\n",
    "\n",
    "class LassoRegression(LinarRegression):\n",
    "    def __init__(self, method, lr, l):\n",
    "        self.regularization = Lasso(l)\n",
    "        super().__init__(self.regularization, lr, method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parent class\n",
    "\n",
    "class Animal:\n",
    "    def __init__(self, name, breed):\n",
    "        self.name = name\n",
    "        self.breed = breed\n",
    "\n",
    "    def speak(self):\n",
    "        print(\"This animal makes sound\")\n",
    "\n",
    "# Child class\n",
    "\n",
    "class Dog(Animal):\n",
    "    def __init__(self, name, breed):\n",
    "        super().__init__(name, breed)\n",
    "    def speak(self):\n",
    "        print(f'{self.name} says: Woof!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dog = Dog('buddy', 'gr')\n",
    "\n",
    "my_dog.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.sign(-200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signature = mlflow.models.infer_signature(X_train, model.predict(X_train))\n",
    "\n",
    "''' \n",
    "Model signature defines schema of model input and output.\n",
    "\n",
    "Log a scikit-learn model as an MLflow artifact for the current run.\n",
    "\n",
    " To manually infer a model signature, call infer_signature() on datasets with valid model inputs, \n",
    " such as a training dataset with the target column omitted, and valid model outputs, like model predictions made on the training dataset\n",
    "\n",
    "'''\n",
    "# mlflow.sklearn.log_model(model, artifact_path='model', signature=signature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "m = 10  # Number of input neurons (fan-in)\n",
    "# Calculate the range for Xavier initialization\n",
    "lower, upper = -(1.0 / np.sqrt(m)), (1.0 / np.sqrt(m))\n",
    "\n",
    "print(lower, upper)  # Print calculated range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 1000 random numbers in [0, 1)\n",
    "numbers = np.random.random(1000)\n",
    "\n",
    "# Scale to the range [lower, upper]\n",
    "scaled = lower + numbers * (upper - lower)\n",
    "\n",
    "print(scaled)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
